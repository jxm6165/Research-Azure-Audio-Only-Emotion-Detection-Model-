{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# WINDOW_SIZE = 257, CODEBOOK_SIZE = 10000\n",
    "\n",
    "enable_norm = False\n",
    "\n",
    "X_train = np.loadtxt(\"MFCC/derived_feature_train.csv\", delimiter = \",\")\n",
    "y_train = np.loadtxt(\"MFCC/derived_label_train.csv\", delimiter = \",\")\n",
    "X_test = np.loadtxt(\"MFCC/derived_feature_test.csv\", delimiter=\",\")\n",
    "y_test = np.loadtxt(\"MFCC/derived_label_test.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_norm:\n",
    "    X_train = np.transpose(X_train)\n",
    "    X_test = np.transpose(X_test)\n",
    "\n",
    "    model_normalizer_horizontal = MinMaxScaler()\n",
    "    model_normalizer_horizontal.fit(X_train)\n",
    "    X_train = model_normalizer_horizontal.transform(X_train)\n",
    "\n",
    "    model_normalizer_horizontal = MinMaxScaler()\n",
    "    model_normalizer_horizontal.fit(X_test)\n",
    "    X_test = model_normalizer_horizontal.transform(X_test)\n",
    "\n",
    "    X_train = np.transpose(X_train)\n",
    "    X_test = np.transpose(X_test)\n",
    "\n",
    "    model_normalizer_vertical = MinMaxScaler()\n",
    "    model_normalizer_vertical.fit(X_train)\n",
    "\n",
    "    X_train = model_normalizer_vertical.transform(X_train)\n",
    "    X_test = model_normalizer_vertical.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'sad']\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "param_grid_ = {'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], \"penalty\":[\"l1\",\"l2\"]}\n",
    "print('-> Processing 10-Fold Cross Validation and Grid Search\\n')\n",
    "\n",
    "bow_search = GridSearchCV(LogisticRegression(), cv=10, param_grid=param_grid_, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "t0 = time()\n",
    "bow_search.fit(X_train, y_train)\n",
    "training_time = round(time()-t0, 3)\n",
    "print('-> Done! Show Grid scores\\n')\n",
    "\n",
    "print(bow_search.cv_results_,'\\n\\n')\n",
    "\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(bow_search.best_params_,'\\n')\n",
    "print(\"Grid scores on development set:\\n\")\n",
    "means = bow_search.cv_results_['mean_test_score']\n",
    "stds = bow_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, bow_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print('\\n\\n')\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\\n\\n\")\n",
    "t0 = time()\n",
    "y_true, y_pred = y_test, bow_search.predict(X_test)\n",
    "test_time = round(time()-t0, 3)\n",
    "cmat = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm           = cmat, \n",
    "                      normalize    = False,\n",
    "                      target_names = label_names,\n",
    "                      cmap = plt.get_cmap('Blues'),\n",
    "                      title        = \"Confusion Matrix LR Dataset_Norm = %s\" % str(enable_norm))\n",
    "plot_confusion_matrix(cm           = cmat, \n",
    "                      target_names = label_names,\n",
    "                      cmap = plt.get_cmap('Blues'),\n",
    "                      title        = \"Normalized Confusion Matrix LR Dataset_Norm = %s\" % str(enable_norm))\n",
    "print('\\n\\n')\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print('Accuracy', metrics.accuracy_score(y_pred,y_test))\n",
    "print(\"Training time : {}\\n\".format(training_time))\n",
    "print(\"Test time : {}\\n\".format(test_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB\n",
    "parameters = {'alpha': (1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100, 1000)}\n",
    "bow_search = GridSearchCV(MultinomialNB(), parameters, cv=10, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "t0 = time()\n",
    "bow_search.fit(X_train, y_train)\n",
    "training_time = round(time()-t0, 3)\n",
    "print('-> Done! Show Grid scores\\n')\n",
    "\n",
    "print(bow_search.cv_results_,'\\n\\n')\n",
    "\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(bow_search.best_params_,'\\n')\n",
    "print(\"Grid scores on development set:\\n\")\n",
    "means = bow_search.cv_results_['mean_test_score']\n",
    "stds = bow_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, bow_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print('\\n\\n')\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\\n\\n\")\n",
    "t0 = time()\n",
    "y_true, y_pred = y_test, bow_search.predict(X_test)\n",
    "test_time = round(time()-t0, 3)\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n')\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print('Accuracy', metrics.accuracy_score(y_pred,y_test))\n",
    "print(\"Training time : {}\\n\".format(training_time))\n",
    "print(\"Test time : {}\\n\".format(test_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "param_grid_ = {'C': [0.001, 0.01, 0.1, 1, 10], \"kernel\":[\"linear\"]}\n",
    "print('-> Processing 10-Fold Cross Validation and Grid Search\\n')\n",
    "\n",
    "bow_search = GridSearchCV(SVC(), cv=10, param_grid=param_grid_, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "t0 = time()\n",
    "bow_search.fit(X_train, y_train)\n",
    "training_time = round(time()-t0, 3)\n",
    "print('-> Done! Show Grid scores\\n')\n",
    "\n",
    "print(bow_search.cv_results_,'\\n\\n')\n",
    "\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(bow_search.best_params_,'\\n')\n",
    "print(\"Grid scores on development set:\\n\")\n",
    "means = bow_search.cv_results_['mean_test_score']\n",
    "stds = bow_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, bow_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print('\\n\\n')\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\\n\\n\")\n",
    "t0 = time()\n",
    "y_true, y_pred = y_test, bow_search.predict(X_test)\n",
    "test_time = round(time()-t0, 3)\n",
    "cmat = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm           = cmat, \n",
    "                      normalize    = False,\n",
    "                      target_names = label_names,\n",
    "                      cmap = plt.get_cmap('Greys'),\n",
    "                      title        = \"Confusion Matrix SVC Dataset_Norm = %s\" % str(enable_norm))\n",
    "plot_confusion_matrix(cm           = cmat, \n",
    "                      target_names = label_names,\n",
    "                      cmap = plt.get_cmap('Greys'),\n",
    "                      title        = \"Normalized Confusion Matrix SVC Dataset_Norm = %s\" % str(enable_norm))\n",
    "print('\\n\\n')\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print('Accuracy', metrics.accuracy_score(y_pred,y_test))\n",
    "print(\"Training time : {}\\n\".format(training_time))\n",
    "print(\"Test time : {}\\n\".format(test_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "param_grid_ = [\n",
    "  {'alpha': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01]} ]\n",
    "bow_search = GridSearchCV(SGDClassifier(max_iter=2), cv=10, param_grid=param_grid_, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "t0 = time()\n",
    "bow_search.fit(X_train, y_train)\n",
    "training_time = round(time()-t0, 3)\n",
    "print('-> Done! Show Grid scores\\n')\n",
    "\n",
    "print(bow_search.cv_results_,'\\n\\n')\n",
    "\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(bow_search.best_params_,'\\n')\n",
    "print(\"Grid scores on development set:\\n\")\n",
    "means = bow_search.cv_results_['mean_test_score']\n",
    "stds = bow_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, bow_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print('\\n\\n')\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\\n\\n\")\n",
    "t0 = time()\n",
    "y_true, y_pred = y_test, bow_search.predict(X_test)\n",
    "test_time = round(time()-t0, 3)\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n')\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print('Accuracy', metrics.accuracy_score(y_pred,y_test))\n",
    "print(\"Training time : {}\\n\".format(training_time))\n",
    "print(\"Test time : {}\\n\".format(test_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "param_grid_ = {\"min_samples_leaf\": [2, 3, 5, 7, 10, 100, 250, 500, 1000]}\n",
    "bow_search = GridSearchCV(RandomForestClassifier(), param_grid=param_grid_, cv=10, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "t0 = time()\n",
    "bow_search.fit(X_train, y_train)\n",
    "training_time = round(time()-t0, 3)\n",
    "print('-> Done! Show Grid scores\\n')\n",
    "\n",
    "print(bow_search.cv_results_,'\\n\\n')\n",
    "\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(bow_search.best_params_,'\\n')\n",
    "print(\"Grid scores on development set:\\n\")\n",
    "means = bow_search.cv_results_['mean_test_score']\n",
    "stds = bow_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, bow_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print('\\n\\n')\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\\n\\n\")\n",
    "t0 = time()\n",
    "y_true, y_pred = y_test, bow_search.predict(X_test)\n",
    "test_time = round(time()-t0, 3)\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n')\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print('Accuracy', metrics.accuracy_score(y_pred,y_test))\n",
    "print(\"Training time : {}\\n\".format(training_time))\n",
    "print(\"Test time : {}\\n\".format(test_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT\n",
    "param_grid_ = {\"min_samples_leaf\": [2, 3, 5, 7, 10, 100, 250, 500, 1000]}\n",
    "bow_search = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid_, cv=10, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "t0 = time()\n",
    "bow_search.fit(X_train, y_train)\n",
    "training_time = round(time()-t0, 3)\n",
    "print('-> Done! Show Grid scores\\n')\n",
    "\n",
    "print(bow_search.cv_results_,'\\n\\n')\n",
    "\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(bow_search.best_params_,'\\n')\n",
    "print(\"Grid scores on development set:\\n\")\n",
    "means = bow_search.cv_results_['mean_test_score']\n",
    "stds = bow_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, bow_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print('\\n\\n')\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\\n\\n\")\n",
    "t0 = time()\n",
    "y_true, y_pred = y_test, bow_search.predict(X_test)\n",
    "test_time = round(time()-t0, 3)\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n')\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print('Accuracy', metrics.accuracy_score(y_pred,y_test))\n",
    "print(\"Training time : {}\\n\".format(training_time))\n",
    "print(\"Test time : {}\\n\".format(test_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "param_grid_ = {'n_neighbors': [1], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}\n",
    "bow_search = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid_, cv=10, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "t0 = time()\n",
    "bow_search.fit(X_train, y_train)\n",
    "training_time = round(time()-t0, 3)\n",
    "print('-> Done! Show Grid scores\\n')\n",
    "\n",
    "print(bow_search.cv_results_,'\\n\\n')\n",
    "\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(bow_search.best_params_,'\\n')\n",
    "print(\"Grid scores on development set:\\n\")\n",
    "means = bow_search.cv_results_['mean_test_score']\n",
    "stds = bow_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, bow_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print('\\n\\n')\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\\n\\n\")\n",
    "t0 = time()\n",
    "y_true, y_pred = y_test, bow_search.predict(X_test)\n",
    "test_time = round(time()-t0, 3)\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n')\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print('Accuracy', metrics.accuracy_score(y_pred,y_test))\n",
    "print(\"Training time : {}\\n\".format(training_time))\n",
    "print(\"Test time : {}\\n\".format(test_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPClassifier\n",
    "clf = MLPClassifier(activation='tanh', alpha=0.03, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(64, 64, 64), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=100000, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=48, shuffle=True,\n",
    "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "       warm_start=False)\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "cmat = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm           = cmat, \n",
    "                      normalize    = False,\n",
    "                      target_names = label_names,\n",
    "                      cmap = plt.get_cmap('Greens'),\n",
    "                      title        = \"Confusion Matrix MLP Dataset_Norm = %s\" % str(enable_norm))\n",
    "plot_confusion_matrix(cm           = cmat, \n",
    "                      target_names = label_names,\n",
    "                      cmap = plt.get_cmap('Greens'),\n",
    "                      title        = \"Normalized Confusion Matrix MLP Dataset_Norm = %s\" % str(enable_norm))\n",
    "print(classification_report(y_true, y_pred))\n",
    "print('Accuracy', metrics.accuracy_score(y_pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
