{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "codebook_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MFCC/normalizer_fit.pkl\", \"rb\") as f:\n",
    "    normalizer_fit = pickle.load(f)\n",
    "    \n",
    "with open(\"MFCC/kmeans_%s.pkl\" % str(codebook_size), \"rb\") as f:\n",
    "    kmeans = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_num = kmeans.cluster_centers_.shape[0]\n",
    "print(\"number of kmeans centers:\", center_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvPath = os.path.abspath(\"MFCC/csv\")\n",
    "labellst = os.listdir(csvPath)\n",
    "for label in labellst:\n",
    "    try:\n",
    "        intlabel = int(label)\n",
    "    except:\n",
    "        labellst.remove(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_feature_train = []\n",
    "derived_label_train = []\n",
    "derived_feature_test = []\n",
    "derived_label_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labellst:\n",
    "    TrainPath = '%s/%s/train' % (csvPath, label)\n",
    "    TestPath = '%s/%s/test' % (csvPath, label)\n",
    "    i, j = 0, 0\n",
    "\n",
    "    for file in os.listdir(TrainPath):\n",
    "        filePath = os.path.join(TrainPath, file)\n",
    "        csv_features = np.loadtxt(filePath, delimiter = \",\")\n",
    "        csv_features = csv_features[~np.isnan(csv_features).any(axis=1)]\n",
    "        \n",
    "        # Normalize the csv_features\n",
    "        norm_features = normalizer_fit.transform(csv_features)\n",
    "        \n",
    "        # Get the kmeans output for each file\n",
    "        kmeans_filter = kmeans.predict(norm_features)\n",
    "        \n",
    "        # Count occurrences and build histogram\n",
    "        unique, counts = np.unique(kmeans_filter, return_counts = True)\n",
    "        canvas = [0] * center_num\n",
    "        for i in range(center_num):\n",
    "            if i in unique:\n",
    "                canvas[i] = counts[np.where(unique == i)][0]\n",
    "            \n",
    "            \n",
    "        derived_feature_train.append(canvas)\n",
    "        derived_label_train.append(int(label))\n",
    "\n",
    "    \n",
    "    for file in os.listdir(TestPath):\n",
    "        filePath = os.path.join(TestPath, file)\n",
    "        csv_features = np.loadtxt(filePath, delimiter = \",\")\n",
    "        csv_features = csv_features[~np.isnan(csv_features).any(axis=1)]\n",
    "        \n",
    "        # Normalize the csv_features\n",
    "        norm_features = normalizer_fit.transform(csv_features)\n",
    "        \n",
    "        # Get the kmeans output for each file\n",
    "        kmeans_filter = kmeans.predict(norm_features)\n",
    "        \n",
    "        # Count occurrences and build histogram\n",
    "        unique, counts = np.unique(kmeans_filter, return_counts = True)\n",
    "        canvas = [0] * center_num\n",
    "        for j in range(center_num):\n",
    "            if j in unique:\n",
    "                canvas[j] = counts[np.where(unique == j)][0]\n",
    "            \n",
    "            \n",
    "        derived_feature_test.append(canvas)\n",
    "        derived_label_test.append(int(label))\n",
    "\n",
    "derived_feature_train = np.array(derived_feature_train).astype(np.float64)\n",
    "derived_label_train = np.expand_dims(derived_label_train, axis=1).astype(np.int32)\n",
    "print(\"derived_feature_train shape:\", derived_feature_train.shape)\n",
    "print(\"derived_label_train shape:\", derived_label_train.shape)\n",
    "np.savetxt(\"MFCC/derived_feature_train.csv\", derived_feature_train, fmt = '%1.3f', delimiter = ',')\n",
    "np.savetxt(\"MFCC/derived_label_train.csv\", derived_label_train, delimiter = ',')\n",
    "\n",
    "derived_feature_test = np.array(derived_feature_test).astype(np.float64)\n",
    "derived_label_test = np.expand_dims(derived_label_test, axis=1).astype(np.int32)\n",
    "print(\"derived_feature_test shape:\", derived_feature_test.shape)\n",
    "print(\"derived_label_test shape:\", derived_label_test.shape)\n",
    "np.savetxt(\"MFCC/derived_feature_test.csv\", derived_feature_test, fmt = '%1.3f', delimiter = ',')\n",
    "np.savetxt(\"MFCC/derived_label_test.csv\", derived_label_test, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_feature_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_feature_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
